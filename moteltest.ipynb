from math import degrees
import math

import operator
from functools import reduce
import numpy as np
import pandas as pd
# import face_recognition
import warnings
import matplotlib.pyplot as plt

from skimage.transform import resize
from skimage.exposure import equalize_adapthist, equalize_hist

import cv2

from classification_models.keras import Classifiers

ResNet18, process_input = Classifiers.get('resnet18')
# model = ResNet18((224, 224, 3), weights = 'imagenet')
class No_Preprocessing:

    def __init__(self, img_width, img_height):
        self.img_width = img_width
        self.img_height = img_height

    def extract_and_prepare_pixels(self, pixels):
        """
        Takes in a string (pixels) that has space separated integer values and returns an array which includes the
        pixels for all images.
        """
        pixels_as_list = [item[0] for item in pixels.values.tolist()]
        np_image_array = []
        for index, item in enumerate(pixels_as_list):
            # split space separated ints
            pixel_data = item.split()
            img_size_row = img_size_col = 256
            if len(pixel_data) % 490 == 0:
                img_size_row = 490
                img_size_col = 640
            elif len(pixel_data) == 10000:
                img_size_row = img_size_col = 100

            data = np.zeros((img_size_row, img_size_col), dtype=np.uint8)

            # Loop through rows
            for i in range(0, img_size_row):
                # (0 = 0), (1 = 47), (2 = 94), ...
                pixel_index = i * img_size_col
                # (0 = [0:47]), (1 = [47: 94]), (2 = [94, 141]), ...
                data[i] = pixel_data[pixel_index:pixel_index + img_size_col]

            np_image_array.append(np.array(data))
        np_image_array = np.array(np_image_array)
        return np_image_array


    def predict_emotion(self, model, img):
        """
        Use a trained model to predict emotional state
        """

        emotion = 'None'

        prediction = model.predict(img)
        prediction_ = np.argmax(prediction)

        if prediction_ == 0:
            emotion = 'Angry'
        elif prediction_ == 1:
            emotion = 'Scared'
        elif prediction_ == 2:
            emotion = 'Happy'
        elif prediction_ == 3:
            emotion = 'Sad'

        d = {'emotion': ['Angry', 'Scared', 'Happy', 'Sad'], 'prob': prediction[0]}
        df = pd.DataFrame(d, columns=['emotion', 'prob'])

        return df


#####
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
# from keras.utils import to_categorical
from tensorflow.keras.utils import to_categorical
from sklearn.utils import shuffle
from keras import Sequential
from keras.regularizers import l2
from keras.layers import Dense, Dropout, Conv2D, Flatten, BatchNormalization, AveragePooling2D, Activation
# from keras.optimizers import SGD
from tensorflow.keras.optimizers import SGD

# size of images
img_width = 100
img_height = 100
# path for results
model_path="/models"

# read image csv
data = pd.read_csv('coding/prep_images_rotated.csv')
data = data.sample(frac=1).reset_index(drop=True)

# print some information
print('Different emotional states: ' + str(np.unique(data.emotion)))
print("Number of Examples for both states")
print(data.emotion.value_counts())

# pixel array is an ndarray containing all pixels of each image
helper = No_Preprocessing(img_width, img_height)
pixels = helper.extract_and_prepare_pixels(data[['pixels']])

t = pixels
x = t.resize(t, (100, 100))
y = to_categorical(data.emotion.reset_index(drop=True))

# build train/test datasets
x_shuffle, y_shuffle = shuffle(x, y)  # Mix samples
x_train, x_test, y_train, y_test = train_test_split(x_shuffle, y_shuffle, test_size=0.1)  # split for train and test block

# train on all
# x_train = x_shuffle
# y_train = y_shuffle

# plot part of the set
fig, ax = plt.subplots(5, 5, figsize=(7, 7))
j = -1
k = 0
for i in range(0, 25):
  if i % 5 == 0:
    j += 1
    k = 0
  print(pixels[i])
  ax[j, k].imshow(pixels[i].reshape(100, 100), cmap="gray", interpolation='nearest')
  ax[j, k].set_title(y[i])
  ax[j, k].axis('off')
  k += 1
plt.savefig(model_path + 'exampleInput.png', dpi=300)

from tensorflow.keras.applications import ResNet50V2

model = ResNet18(include_top=True, weights=None, input_shape=(100, 100, 1), pooling= max, classes=4)
model.compile(loss='categorical_crossentropy', 
              metrics=['accuracy'], 
              optimizer='adam') 
history = model.fit(x_train, y_train, validation_split=0.2, epochs=100, batch_size=16)

scores = model.evaluate(x_test, y_test)
print("\n%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))

# save trained classifier
model.save(model_path + 'ResNet_101_classifier.h5')

# ---------------------------------------------------------------------------------------
# plotting

# summarize history for accuracy
plt.close()
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.savefig(model_path + 'accuracy.png', dpi=300)

# summarize history for loss
plt.close()
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.savefig(model_path + 'loss.png', dpi=300)
